{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os, cv2, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/home/Addy/MURA-v1.1/training/'\n",
    "\n",
    "ROWS = 244\n",
    "COLS = 244\n",
    "CHANNELS = 3\n",
    "\n",
    "MURA_train = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data\n",
    "\n",
    "train = prep_data(MURA_train)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image), (299,299)))#, interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'positive' in i:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = prepare_data(MURA_train)\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)\n",
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X), Y, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X), Y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions\n",
    "base_model=VGG19(include_top=False,weights='imagenet')\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_features = Input(base_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_model.get_output_shape_at(0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_features = BatchNormalization()(pt_features)\n",
    "# here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "attn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\n",
    "attn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n",
    "attn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\n",
    "attn_layer = Conv2D(1, \n",
    "                    kernel_size = (1,1), \n",
    "                    padding = 'valid', \n",
    "                    activation = 'sigmoid')(attn_layer)\n",
    "# fan it out to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.5)(gap)\n",
    "gap_features1 = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask1 = GlobalAveragePooling2D()(attn_layer)\n",
    "#to account for missing values from the attention model\n",
    "gap1 = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features1, gap_mask1])\n",
    "gap_dr1 = Dropout(0.5)(gap1)\n",
    "gap_features2 = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask2 = GlobalAveragePooling2D()(attn_layer)\n",
    "gap2 = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features2, gap_mask2])\n",
    "gap_dr2 = Dropout(0.5)(gap2)\n",
    "\n",
    "dr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr2))\n",
    "out_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n",
    "\n",
    "attn_model.compile(optimizer = Adam(lr = 1e-3, beta_1=0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = True),\n",
    "              loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = 'combined_model')\n",
    "model.add(base_model)\n",
    "model.add(attn_model)\n",
    "model.compile(optimizer = Adam(lr = 1e-3, beta_1=0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = True),\n",
    "              loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('VGG19-Attention-best.hdf5',\n",
    "                monitor='val_binary_accuracy', verbose=1, save_best_only=True, \n",
    "                save_weights_only=True, mode='max', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size, \n",
    "                              epochs=200, callbacks=callbacks_list, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('VGG-Attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
